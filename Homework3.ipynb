{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7caf16d-4a7c-4c62-8818-a662add5d738",
   "metadata": {},
   "source": [
    "## Домашнее задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18977ebd-34c6-4359-9e04-b17dd8acdd1d",
   "metadata": {},
   "source": [
    "#### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a19ce-7d36-49e6-a0c1-bcb23224dbbe",
   "metadata": {},
   "source": [
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и Y из этих данных.\n",
    "Разбейте эти датафреймы н а тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185cb609-9c28-400c-a4c8-8565cfa11981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1492435a-d0eb-4755-b60a-c4e15ca6f7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4      5     6       7    8      9     10\n",
       "0    0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3\n",
       "1  396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "2    0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8\n",
       "3  396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "4    0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c86e8a-fbb4-4dfd-9866-62380c6efd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([df.values[::2, :], df.values[1::2, :2]])\n",
    "y = df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a3971f-5a8a-4270-93da-a511e99bc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f031d0-5167-4857-b98f-184d7dfbcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91236531-a307-4d8c-b6bd-5cfa0d839aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71122600574849"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_lr = r2_score(y_test, y_hat)\n",
    "r2_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00353b6-446e-4d02-b1e1-224bb617d558",
   "metadata": {},
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e6425-8311-4ff0-a84d-9abaf02d77ee",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy, так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма. \n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d78df7-1b56-4f66-ac5b-9752e52dfb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 1000, max_depth = 12, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "r2_rf = r2_score(y_test, y_hat)\n",
    "r2_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef9125-0fe5-4b4c-8c06-dec0440d2c02",
   "metadata": {},
   "source": [
    "Чтобы ответить на вопрос о том, какая модель лучше, сначала проверим, являются ли статистически значимыми наши результаты. Для этого проведем F-test Фишера, нулевая гипотеза которого состоит в том, что между факторами и целевой переменной нет зависимости, а полученный коэффициент детерминации имеет значение, обусловленное статистическим выбросом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f5c857-5f4f-4db5-9e01-47a3066a3095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.144797487921622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = X_test.shape[1]\n",
    "n = X_test.shape[0]\n",
    "F_statistic_lr = (r2_lr / m) / ((1 - r2_lr) / (n - m - 1))\n",
    "F_statistic_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf57f0d-9f95-4f25-b66b-b5f2b7d0bf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7916927725085028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "alpha = 0.05\n",
    "k1 = m\n",
    "k2 = n - m - 1\n",
    "t = stats.f.ppf(1 - alpha, k1, k2)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff44ff1-ea18-46b2-b2f4-0b857639d2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1102230246251565e-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value = 1 - stats.f.cdf(F_statistic_lr,  k1, k2)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed42169-a0c5-4670-b74d-de2318449dfa",
   "metadata": {},
   "source": [
    "При уровне значимости 0.05 критическая область начинается с значения статистики 1.79. Полученная статистика на основе нашего коэффициента детерминации равна 24.14, что находится далеко в критической области (p_value = 1.1102230246251565e-16). Нулевая гипотеза опровергнута, результаты статистически значимы. Так как коэффициент для Random Forest выше, качество этой модели выше, чем у модели линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48d7dd-4516-4c9b-80e8-41e931014c5d",
   "metadata": {},
   "source": [
    "#### Задание 3\n",
    "\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf70529-ad3b-4abb-a7ba-2f36c52e21d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ?RandomForestRegressor\n",
    "# нас интересует вот эта часть вывода\n",
    "\"\"\"\n",
    "feature_importances_ : ndarray of shape (n_features,)\n",
    "    The impurity-based feature importances.\n",
    "    The higher, the more important the feature.\n",
    "    The importance of a feature is computed as the (normalized)\n",
    "    total reduction of the criterion brought by that feature.  It is also\n",
    "    known as the Gini importance.\n",
    "\n",
    "    Warning: impurity-based feature importances can be misleading for\n",
    "    high cardinality features (many unique values). See\n",
    "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66b5312a-4b92-447f-a1fc-8fbfa4a15218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03167574, 0.00154252, 0.00713813, 0.00123624, 0.01426897,\n",
       "       0.40268179, 0.01429864, 0.06397257, 0.00528122, 0.01152493,\n",
       "       0.01808108, 0.01245085, 0.41584732])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc09c775-450f-4c3f-9832-0beba4f64f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "765f4714-18b1-410b-b1d2-981985b970d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(model.feature_importances_)[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13386298-01fc-4952-9c46-fdb438d66de4",
   "metadata": {},
   "source": [
    "Наибольшее значение имеют признаки 5 и 12, а именно:\n",
    "\n",
    "RM - average number of rooms per dwelling\n",
    "\n",
    "LSTAT - % lower status of the population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de7bce-4aeb-4381-8bb2-a91720a25193",
   "metadata": {},
   "source": [
    "#### Задание 4\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими. Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "\n",
    "\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "\n",
    "\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5),'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3.\n",
    "\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score. Вычислите AUC на тестовых данных и сравните с результатом, полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb51ade9-d530-4458-bd50-3e20e69ffa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56f693d-34e7-41e2-a49b-e771cba9ee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914487d4-ab1a-4ab7-b6be-377e243a903e",
   "metadata": {},
   "source": [
    "Датафрейм очень сильно разбалансирован по классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4beaa5f8-9f1c-4a98-a0d1-5d08fe000641",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e99efb-0aae-4eba-9a2b-ba04d6ebf9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e115d-2f79-49b4-9d4c-2ad0280dbfb3",
   "metadata": {},
   "source": [
    "Пустых значений нет, все значения числовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3af3b590-c237-4628-aca2-e7db8937558a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb970153-15ae-4a4b-a893-e204c09debc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pandas.core.series.Series)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df['Class']\n",
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30732745-7238-498e-adf6-38d625fe00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daee14b3-adb0-43d4-8757-69a10cfe399e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 30), (85443, 30), (199364,), (85443,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63367671-8e0c-481f-b7d8-b7a556418ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a12453cf-a51f-45b5-bd38-5589754d8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb497b82-c542-4d6b-b0e5-aa78fbb05235",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5),'max_depth': np.arange(4, 7)}]\n",
    "estimator=RandomForestClassifier(random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "078f6970-3c82-4952-ba8f-2a162a003977",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator, param_grid=parameters, scoring='roc_auc', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1053803c-c146-4e9a-ae23-550b96b3e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
       "                          'max_features': array([3, 4]),\n",
       "                          'n_estimators': [10, 15]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f65adede-2a51-49b8-88b1-1f862d3b628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d02de061-b487-4785-913a-6bcfb12bbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f451d5e6-7feb-455d-b5b4-2e3b45a270f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "218e930b-cf6a-42dc-a0a2-9b31149f2420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462664156037156"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36dd13b1-85b5-4efc-b5e5-eb9ab8923b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = clf.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "210dfedb-3c91-401c-8ea6-f346d5273c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703527882554751"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_pred_proba_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e33ece-d452-4804-a97c-5a6023f21197",
   "metadata": {},
   "source": [
    "На тренировочном датасете roc_auc_score ожидаемо выше, чем на тестовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3f4f3-fb05-4a6b-ba48-3a043c17e71e",
   "metadata": {},
   "source": [
    "### Задание 5\n",
    "\n",
    "В этом задании мы будем работать с датасетом, из встроенных датасетов sklearn.datasets load_digits. Изучите, что это за датасет, поймите, что это за задача (регрессия или классификация), изобразите первые 10 объектов из данных с помощью matplotlib.\n",
    "\n",
    "Разбейте датасет на тренировочный и тестовый наборы данных.\n",
    "\n",
    "Обучите наиболее понравившуюся вам модель машинного обучения и подберите лучшие гиперпараметры.\n",
    "Посчитайте подходящие метрики качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91b63707-de5a-4da5-9c89-502766fbe7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02a0fb4b-137a-493a-961d-76a293f5411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acdc39f8-0617-42e1-b84a-8d10f52d9931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7878643e-d45c-4964-a172-05a8fd97c72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = digits.data, digits.target\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa079f61-b64e-44ff-b516-7fe5a59d3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (1797, 8, 8))\n",
    "MV = X.mean(axis=0)\n",
    "Stdev = np.sqrt(np.power(X - MV, 2).mean(axis=0) + 1e-10)\n",
    "X = (X - MV) / Stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c23dcfe-552f-45ef-b99a-d5d497b4ef93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.313254319296798e-18, 0.9762812065967328)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(), X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54e3e0d7-a438-4deb-8663-8943c3f1278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=100, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c57a4f-9685-4f38-9f1a-bba0f7ef2981",
   "metadata": {},
   "source": [
    "Напишем свою нейросетку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c147ae77-8b80-4cdb-82a9-4bb3a5b6fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_multiclass:\n",
    "    \n",
    "    \"\"\"Same as Network class except for CELoss support\n",
    "    \n",
    "    inference_mode() and train_mode() methods were introduces to support BatchNorm layer switch of regimes. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0):\n",
    "        for layer in reversed(self.layers):\n",
    "            upstr_grad = layer.backward(upstr_grad, lr = lr, debug = debug)\n",
    "        return upstr_grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y_hat = self.forward(X).argmax(axis = 1)\n",
    "        return Y_hat\n",
    "    \n",
    "    def inference_mode(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, BatchNorm):\n",
    "                layer.inference = True\n",
    "    \n",
    "    def train_mode(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, BatchNorm):\n",
    "                layer.inference = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ce758a9-83a2-4a73-af1d-d6843be068c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"Fully Connected Layer. \n",
    "    \n",
    "    \n",
    "    Initializer's parameters:\n",
    "    inp -- the number of input neurons\n",
    "    out -- the number of output neurons\n",
    "    \n",
    "    The weights are initialized as in PyTorch.\n",
    "    \n",
    "    forward() parameters:\n",
    "    X -- matix of shape (N, inp), where N is the size of a batch\n",
    "    \n",
    "    backward() parameters:\n",
    "    upstr_grad -- upstream (incoming) gradients from the layer closer to the end of the network\n",
    "    lr -- learning rate\n",
    "    debug -- debug level. debug == 2 shows gradients on every learning step.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        self.inp = inp\n",
    "        self.out = out\n",
    "        stdv = 1.0 / np.sqrt(inp)\n",
    "        self.W = np.random.default_rng().uniform(-stdv, stdv, (inp, out)).astype(np.float32)\n",
    "        self.X_ = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X_ = X.astype(np.float32)\n",
    "        return np.dot(X.astype(np.float32), self.W)\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0): \n",
    "        # gradients are averaged by batch size, since if we not do it, the deltas will grow proportionally to batch size\n",
    "        delta_W = np.dot(np.transpose(self.X_), upstr_grad.astype(np.float32)) / self.X_.shape[0]\n",
    "        \n",
    "        self.W += (-1) * lr * delta_W # multiply by -1 to move in the opposite of gradient direction\n",
    "        if debug == 2: print(f'Linear Layer: W gradients = {delta_W}')\n",
    "        if debug == 2: print(f'Linear Layer: new weights = {self.W}')\n",
    "        return np.dot(upstr_grad.astype(np.float32), np.transpose(self.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d03768-f9c4-45de-b3d3-215f07817191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm:\n",
    "    \"\"\" Batch normalization layer (as per https://arxiv.org/pdf/1502.03167.pdf)\n",
    "    Normalizes, i.e. achieves zero mean and standard deviation of 1 using mini-batch statistics for every pixel along the batch direction.\n",
    "    \n",
    "    Attibutes and parameters:\n",
    "    self.inference - whether the layer is in inference mode\n",
    "    self.m and self.v - mean and variance of the whole training set calculated as moving average during training\n",
    "    self.g and self.b - gamma and beta used for scaling and shifting normalized inputs. These parameters are learnable and for each mini-batch\n",
    "        a gradient step is done, see backward() method.\n",
    "    self.mu, self.var - mean and variance of a mini-batch. They have the same dimension as input image in a batch as they are calculated per-pixel\n",
    "    self.momentum - momentum used for moving average calculation\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inference = False\n",
    "        self.g = 1\n",
    "        self.b = 1\n",
    "        self.m = 0\n",
    "        self.v = 0    \n",
    "        self.mu = None\n",
    "        self.var = None\n",
    "        self.X_ = None\n",
    "        self.X_norm_ = None\n",
    "        self.momentum = 0.1\n",
    "        \n",
    "    def forward(self, X):\n",
    "        eps = 1e-10\n",
    "        if not self.inference:\n",
    "            self.X_ = X\n",
    "            self.mu = X.mean(axis=0)\n",
    "            self.var = np.power(X - self.mu, 2).mean(axis = 0)\n",
    "            \n",
    "            self.m = (1 - self.momentum) * self.m + self.momentum * self.mu\n",
    "            self.v = (1 - self.momentum) * self.v + self.momentum * self.var\n",
    "\n",
    "            X_norm = (X - self.mu) / np.sqrt(self.var + eps)\n",
    "            self.X_norm_ = X_norm\n",
    "            return X_norm * self.g + self.b\n",
    "        \n",
    "        else:\n",
    "            return X * self.g / np.sqrt(self.v + eps) + (self.b - self.g * self.m / np.sqrt(self.v + eps))\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0):\n",
    "        eps = 1e-10\n",
    "        dldX_norm = upstr_grad * self.g\n",
    "        \n",
    "        # remember that self.var is a matrix and self.mu is a matrix, hence dldvar and dldmu are also matrixes.\n",
    "        # the formulas for gradient calculations are provided in the original paper\n",
    "        \n",
    "        dldvar = (dldX_norm * (self.X_ - self.mu) * (-1/2) * np.power(self.var + eps, -3/2)).sum(axis=0)\n",
    "        dldmu = dldX_norm * (-1) / np.sqrt(self.var + eps).sum(axis=0) + dldvar * 1/self.X_.shape[0] * ((-2) * (self.X_ - self.mu)).sum(axis=0)\n",
    "        dldX = dldX_norm * 1 / np.sqrt(self.var + eps) + dldvar * 1 / self.X_.shape[0] * 2 * (self.X_ - self.mu) + dldmu * 1 / self.X_.shape[0]\n",
    "        dldg = (upstr_grad * self.X_norm_).sum(axis=0)\n",
    "        dldb = upstr_grad.sum(axis=0)\n",
    "        \n",
    "        self.g += (-1) * lr * dldg\n",
    "        self.b += (-1) * lr * dldb\n",
    "        return dldX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7579ba5-ae44-4882-a156-a6f26f2246e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyRelu:\n",
    "    \n",
    "    \"\"\"Non-linearity equivalent to Relu, but having non-zero behaviour in negative zone with alpha coefficient\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.X_ = None\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X_ = X\n",
    "        return np.where(X <= 0, X * self.alpha, X)\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = None, debug = 0):\n",
    "        return upstr_grad * np.where(self.X_ <= 0, self.alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14201301-bb5f-4711-83bb-0f9b4e6c7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CELoss(Y_true, Y_hat):\n",
    "    \"\"\" Cross-Entropy loss function\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    Y_true -- true labels of a training set. Matrix of shape (N, T), where N is the batch size, T is the number of classes. \n",
    "        0 everywhere except for the correct class where it is 1\n",
    "    Y_hat -- model's predictions. Matrix of shape (N, T), where N is the batch size, T is the number of classes. \n",
    "        Contains probabilities of classes in range [0, 1]\n",
    "    \n",
    "    Returns a tuple of scalar loss value and a matrix of gradients of shape (N, T)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    eps = 1e-10\n",
    "    Y_loss = -np.log2(Y_hat + eps)\n",
    "    Y_grad = -1 / (np.log(2) * Y_hat + eps)\n",
    "    loss = Y_loss * Y_true\n",
    "    grad = Y_grad * Y_true\n",
    "    return loss.sum(), grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e110ba02-18db-48a5-9aad-903183a4ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sm_jacobian(sm_out):\n",
    "    \"\"\" Calculates Jacobian matrix for SoftMax\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    sm_out -- an output of a SoftMax layer, cached during a forward pass. A matrix of shape (number of classes, 1)\n",
    "    If SoftMax input was a batch of shape (N x number of classes), every row of this matrix shall be a separate input for this function\n",
    "    \n",
    "    Returns a Jacobian of shape (number of classes x number of classes)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    jac = np.zeros((sm_out.shape[0], sm_out.shape[0]))\n",
    "    for i in range(sm_out.shape[0]):\n",
    "        for j in range(sm_out.shape[0]):\n",
    "            if i == j:\n",
    "                jac[i, j] = sm_out[i] * (1 - sm_out[i])\n",
    "            else:\n",
    "                jac[i, j] = -1 * sm_out[i] * sm_out[j]\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5ba547d-9df6-406f-979d-bf5182aa97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\" SoftMax layer\n",
    "    \n",
    "    \n",
    "    Supports only batches of size >= 2\n",
    "    \n",
    "    Using cached during forward pass values of output, on backward pass forms Jacobians of partial derivatives with a help of create_sm_jacobian(). \n",
    "    Since N such Jacobians form a matrix of shape (N x number of classes x number of classes), dot product of such a matrix by incoming gradients \n",
    "    is only possible pairwise: one row of incoming gradient shall be multiplied by a single Jacobian.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        exps = np.exp(X)\n",
    "        sum_col = np.reshape(np.sum(exps, axis = 1), (-1, 1))\n",
    "        sums = sum_col\n",
    "        for i in range(X.shape[1] - 1):\n",
    "            sums = np.concatenate((sums, sum_col), axis = 1)\n",
    "        self.out = exps / sums\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, upstream_grad, lr = None, debug = 0):\n",
    "        gradients = np.array([])\n",
    "        for ug, sm_out in zip(upstream_grad, self.out):\n",
    "            SMJ = create_sm_jacobian(sm_out)\n",
    "            grad = np.dot(ug, SMJ)\n",
    "            gradients = np.append(gradients, grad)\n",
    "        return np.reshape(gradients, (upstream_grad.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a17d01d-fb13-4259-8995-c97d8b54c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_enc(vec, num_classes):\n",
    "    \n",
    "    \"\"\"Converts a vector of scalar number of classes into a matrix of one-hot-encoded vectors\"\"\"\n",
    "    \n",
    "    assert len(vec.shape) == 2 and vec.shape[1] == 1, 'only [N x 1] vectors are supported'\n",
    "    \n",
    "    result = np.zeros((vec.shape[0], num_classes))\n",
    "    np.put_along_axis(result, vec, 1, axis = 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ec34325-a68b-4221-bbfd-ec6aac9d2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_conv(Net, X_train, Y_train, batch_size = 8, lr = 1, criterion = 0.001, max_iter = 50, debug = 0):\n",
    "    \n",
    "    \"\"\"Same as train_network() but takes into account SoftMax as the last layer and uses CELoss\"\"\"\n",
    "    \n",
    "    batch_loss = 1e3\n",
    "    iteration = 0\n",
    "    Y_train_enc = one_hot_enc(np.reshape(Y_train, (-1, 1)), 10)\n",
    "    average_loss = 1e3\n",
    "    lmbd = 0.1\n",
    "    \n",
    "    while average_loss > criterion and iteration < max_iter:\n",
    "        \n",
    "        batch_index = random.sample([i for i in range(len(X_train))], batch_size)\n",
    "        Y_hat = Net.forward(X_train[batch_index])\n",
    "        batch_loss, grad = CELoss(Y_train_enc[batch_index], Y_hat)\n",
    "        \n",
    "        if iteration == 0:\n",
    "            average_loss = batch_loss\n",
    "        else:\n",
    "            average_loss = batch_loss * lmbd + (1 - lmbd) * average_loss\n",
    "        \n",
    "        period = math.ceil(max_iter / 30)\n",
    "        if iteration % period == 0: print(f'iteration {iteration}, average_loss = {average_loss}')\n",
    "        Net.backward(grad, lr = lr, debug = debug)\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1ccef57-3361-4675-8ce7-5b344d89a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    \"\"\"Flatten layer \n",
    "    \n",
    "    \n",
    "    Reshapes matrix values on forward pass into a single vector appropriate to be an inpuf for a Fully-Connected Layer.\n",
    "    On backward pass implements the reverse operation. Supports matrixes of shape (Height x Width) and (Batch_size x Height x Width)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_dims = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.input_dims = X.shape\n",
    "        if len(X.shape) == 2:\n",
    "            return X.flatten()\n",
    "        elif len(X.shape) == 3:\n",
    "            result = []\n",
    "            for arr in X:\n",
    "                result.append(arr.flatten())\n",
    "            return np.array(result)\n",
    "        else:\n",
    "            print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "            return None\n",
    "            \n",
    "    \n",
    "    def backward(self, upstr_grad, lr = None, debug = 0):\n",
    "        return np.reshape(upstr_grad, self.input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d28eb09-01a7-4b89-8030-b997bc62543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(X):\n",
    "    \"\"\"pads input image with one pixel of zeros at every edge\n",
    "    \n",
    "    \n",
    "    Supports 2-d input (one-channel images) and 3-d input (batches of one-channel images)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(X.shape) == 2:\n",
    "        X_pad = np.zeros((X.shape[0] + 2, X.shape[1] + 2))\n",
    "        X_pad[1:-1,1:-1] = X\n",
    "        return X_pad\n",
    "    elif len(X.shape) == 3:\n",
    "        result = []\n",
    "        for img in X:\n",
    "            img_pad = np.zeros((img.shape[0] + 2, img.shape[1] + 2))\n",
    "            img_pad[1:-1,1:-1] = img\n",
    "            result.append(img_pad)\n",
    "        return np.array(result)\n",
    "    else:\n",
    "        print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e5167e8-2798-4bfb-b8db-73608f4de6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K, pad = False):\n",
    "    \n",
    "    \n",
    "    \"\"\"Convolutional operation on 2-d input X and 2-d kernel K\"\"\"\n",
    "    \n",
    "    \n",
    "    if pad:\n",
    "        X = pad_with_zeros(X)\n",
    "        \n",
    "    h, w = X.shape[0], X.shape[1]\n",
    "    k1, k2 = K.shape[0], K.shape[1]\n",
    "    result = np.zeros((h - k1 + 1, w - k2 + 1))\n",
    "    \n",
    "    for i in range(0 + k1 - 1, result.shape[0] + k1 - 1):\n",
    "        for j in range(0 + k2 - 1, result.shape[1] + k2 - 1):\n",
    "            result[i - k1 + 1, j - k2 + 1] = (X[i - k1 + 1: i + 1, j - k2 + 1: j + 1] * K).sum()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46898dea-1b1d-4d03-be50-28e2910ad7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot180(X):\n",
    "    return np.rot90(np.rot90(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "843155f5-b1a9-475d-adc6-3c5ad35f0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    \"\"\" Convolution layer\n",
    "    \n",
    "    \n",
    "    Makes convolution operation with 2- or 3-dimensional input and 2-dimensional kernel.\n",
    "    \n",
    "    Init Parameters:\n",
    "    kernel_size - height (width) of the kernel. Only square kerlnels are supported.\n",
    "    pad - whether to pad an input image with zeros\n",
    "    \n",
    "    forward() parameters:\n",
    "    X - input vector of size height x width or batch_size x height x width. Only one-channel images are supported.\n",
    "    \n",
    "    backward() parameters:\n",
    "    upstr_grad -- upstream (incoming) gradients from the layer closer to the end of the network\n",
    "    lr -- learning rate\n",
    "    debug -- debug level. debug == 2 shows gradients on every learning step.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size = 3, pad = False):\n",
    "        # pytorch-stryle weights initialization\n",
    "        n = kernel_size**2\n",
    "        self.kernel = np.random.normal(0, math.sqrt(2. / n), (kernel_size, kernel_size)).astype(np.float32)\n",
    "        self.pad = pad\n",
    "        self.X_ = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if len(X.shape) == 2:\n",
    "            if self.pad: \n",
    "                X = pad_with_zeros(X)\n",
    "            self.X_ = X\n",
    "            return conv2d(X, self.kernel)\n",
    "        \n",
    "        elif len(X.shape) == 3:\n",
    "            if self.pad: \n",
    "                X = pad_with_zeros(X)\n",
    "            self.X_ = X\n",
    "            result = []\n",
    "            for img in X:\n",
    "                result.append(conv2d(img, self.kernel))\n",
    "            return np.array(result)\n",
    "                    \n",
    "        else:\n",
    "            print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "            return None\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0):\n",
    "        if len(upstr_grad.shape) == 2:\n",
    "            # calculate grads w.r.t. weights\n",
    "            grad_w = conv2d(self.X_, rot180(upstr_grad))\n",
    "            if debug == 1: print(f'Conv: grad_w.shape = {grad_w.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_w = {grad_w}')\n",
    "\n",
    "            # calculate grads w.r.t. input\n",
    "            for i in range(self.X_.shape[0] - self.kernel.shape[0] - self.pad):\n",
    "                upstr_grad = pad_with_zeros(upstr_grad)\n",
    "            grad_x = conv2d(upstr_grad, rot180(self.kernel))\n",
    "            if debug == 1: print(f'Conv: grad_x.shape = {grad_x.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_x = {grad_x}')\n",
    "\n",
    "            self.kernel += -1 * grad_w * lr # домножаем на -1, так как градиентный шаг выполняется в направлении антиградиента\n",
    "            return grad_x\n",
    "        \n",
    "        elif len(upstr_grad.shape) == 3:\n",
    "            # calculate grads w.r.t. weights\n",
    "            grad_w_batch = []\n",
    "            for i in range(upstr_grad.shape[0]):\n",
    "                grad_w = conv2d(self.X_[i], rot180(upstr_grad[i]))\n",
    "                grad_w_batch.append(grad_w)\n",
    "            grad_w_batch = np.array(grad_w_batch)\n",
    "            \n",
    "            if debug == 1: print(f'Conv: grad_w_batch.shape = {grad_w_batch.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_w_batch = {grad_w_batch}')\n",
    "            \n",
    "             # calculate grads w.r.t. input\n",
    "            grad_x_batch = []\n",
    "            for i in range(upstr_grad.shape[0]):\n",
    "                ug = upstr_grad[i]\n",
    "                for j in range(2 - self.pad):    \n",
    "                    ug = pad_with_zeros(ug)\n",
    "                grad_x = conv2d(ug, rot180(self.kernel))\n",
    "                grad_x_batch.append(grad_x)\n",
    "            grad_x_batch = np.array(grad_x_batch)\n",
    "            if debug == 1: print(f'Conv: grad_x_batch.shape = {grad_x_batch.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_x_batch = {grad_x_batch}')\n",
    "            return grad_x_batch\n",
    "            \n",
    "            self.kernel += -1 * grad_w_batch.mean(axis = 0) * lr # multiply by -1 as we need to go in the opposite to gradient direction\n",
    "        \n",
    "        else:\n",
    "            print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d935eca-db5f-497f-85fa-b3a87942f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, average_loss = 26.40029215812683\n",
      "iteration 67, average_loss = 23.25394762929451\n",
      "iteration 134, average_loss = 19.11533850454228\n",
      "iteration 201, average_loss = 16.605963681517785\n",
      "iteration 268, average_loss = 13.973909747692643\n",
      "iteration 335, average_loss = 13.659075595291226\n",
      "iteration 402, average_loss = 12.44100342905044\n",
      "iteration 469, average_loss = 12.211628936619912\n",
      "iteration 536, average_loss = 11.471295111699353\n",
      "iteration 603, average_loss = 10.557101048324869\n",
      "iteration 670, average_loss = 9.259568645582771\n",
      "iteration 737, average_loss = 8.282563098200693\n",
      "iteration 804, average_loss = 8.733064601458487\n",
      "iteration 871, average_loss = 7.5034407776355865\n",
      "iteration 938, average_loss = 7.990671196982853\n",
      "iteration 1005, average_loss = 8.318523877888602\n",
      "iteration 1072, average_loss = 7.166896919680346\n",
      "iteration 1139, average_loss = 7.679297555245281\n",
      "iteration 1206, average_loss = 8.221322445869195\n",
      "iteration 1273, average_loss = 6.962903076047162\n",
      "iteration 1340, average_loss = 8.464373513141785\n",
      "iteration 1407, average_loss = 6.417052355564765\n",
      "iteration 1474, average_loss = 7.337656142571964\n",
      "iteration 1541, average_loss = 7.019912196490166\n",
      "iteration 1608, average_loss = 6.459693853963085\n",
      "iteration 1675, average_loss = 7.082858727087823\n",
      "iteration 1742, average_loss = 5.661010310978938\n",
      "iteration 1809, average_loss = 6.6369761342733895\n",
      "iteration 1876, average_loss = 5.342029479698882\n",
      "iteration 1943, average_loss = 7.780662123689852\n"
     ]
    }
   ],
   "source": [
    "NNConv_batch = Network_multiclass([ConvLayer(pad = True), BatchNorm(), LeakyRelu(alpha=0.2), \n",
    "                          ConvLayer(pad = True), BatchNorm(), LeakyRelu(alpha=0.2), \n",
    "                          ConvLayer(pad = True), BatchNorm(), LeakyRelu(alpha=0.2), \n",
    "                          Flatten(), Linear(64, 30), BatchNorm(), LeakyRelu(alpha=0.2), Linear(30, 10), Softmax()])\n",
    "\n",
    "NNConv_batch.train_mode()\n",
    "train_network_conv(NNConv_batch, train_X, train_Y, lr = 0.003, criterion = 0.1, max_iter = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48e3ef59-9fdd-40a7-8fd6-3f8c1ee8dbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 0.8558531746031747, 0.8552772227772228)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "Y_hat = NNConv_batch.forward(test_X)\n",
    "Y_hat = np.argmax(Y_hat, axis = 1)\n",
    "accuracy_score(test_Y, Y_hat), precision_score(test_Y, Y_hat, average = \"macro\"), recall_score(test_Y, Y_hat, average = \"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1166dd02-42d4-459d-a5fe-b31e0ffa7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(test_Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "872c375d-b655-4e03-9fa1-1bcc67bb2cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from string import ascii_uppercase\n",
    "from pandas import DataFrame\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lines = [\"true \"+str(i) for i in range(10)]\n",
    "columns = [\"pred \"+str(i) for i in range(10)]\n",
    "conf_df = DataFrame(conf, index=lines, columns=columns)\n",
    "plt.figure(figsize = (12,8))\n",
    "ax = sn.heatmap(conf_df, cmap='Oranges', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e7e94-26cb-479c-af13-42eb4696dd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
